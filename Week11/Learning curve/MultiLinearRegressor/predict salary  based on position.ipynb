{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SS=StandardScaler()\n",
    "from sklearn.preprocessing import *\n",
    "# from sklearn \n",
    "import importlib.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "# for error calculation MSE or MAE or Rsquare\n",
    "from sklearn.metrics import *\n",
    "# for spllititing the data_set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# For support support vector regression\n",
    "from sklearn.svm import SVR\n",
    "# for time execution calculation\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import learning_curve, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, label_binarize\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(\"DataPreprocessing\", \"/home/admin1/PycharmProjects/Machine_learning_Python/Utility/DataPreprocessing.py\")\n",
    "#At home windows\n",
    "# spec = importlib.util.spec_from_file_location(\"DataPreprocessing\", \"C:/Users/PRAYAS/PycharmProjects/Machine_Learning_Python/Utility/DataPreprocessing.py\")\n",
    "# C:\\Users\\PRAYAS\\PycharmProjects\\Machine_Learning_Python\\Utility\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(foo)\n",
    "preprocess_obj = foo.DataPreprocessing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/bike_sharing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.heatmap(dataframe.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['dteday'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=dataframe.drop(['hum','dteday'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "dataframe.boxplot(rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial without removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframe.hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.nunique()\n",
    "dataframe=dataframe.rename(columns={'cnt':'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest_Regression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trees = 300\n",
    "        print(\"Random Forest Regression\")\n",
    "        \n",
    "    def plotter(self,X,Y,reg,plot_title):\n",
    "        # smoothening the plot so that we can see a smooth curve so getting points with difference 0.1\n",
    "        X_smooth = np.arange(X.min(),X.max(),0.01)\n",
    "        plt.title(plot_title)\n",
    "        if reg != '':\n",
    "            plt.plot(X_smooth,reg.predict(X_smooth.reshape(-1,1)),color='r')\n",
    "        else:\n",
    "#             Y_smooth = np.arange(Y.min(),Y.max(),0.01)\n",
    "            plt.plot(X,Y,color='g')            \n",
    "    \n",
    "    def Random_Forest_Regression_demo(self,dataframe):\n",
    "        # creating Linear regression object\n",
    "        reg = RandomForestRegressor(n_estimators=self.trees,random_state=0)\n",
    "        # creating decision regression object with random state =0 as if same function operated any where it'll give same resukt on the same set\n",
    "\n",
    "        # Splitting independent variables and the output variables\n",
    "        train_data = (dataframe.drop('y')).values\n",
    "        train_Y = dataframe['y'].values\n",
    "        # spilling train and test data\n",
    "        train_data, test_data, train_Y, test_Y = train_test_split(train_data,train_Y, test_size=0.2,random_state=0)\n",
    "        # geting the values of x till the degree provided\n",
    "        \n",
    "        reg.fit(train_data.reshape(-1,1),train_Y.reshape(-1,1))\n",
    "        \n",
    "        # predicting the values on basis of our input data\n",
    "        Ypred = reg.predict(test_data.reshape(-1,1))\n",
    "         \n",
    "        print(\"The value for 6.5 is \", reg.predict(np.array(6.5).reshape(-1,1)))\n",
    "        \n",
    "         # error calculations\n",
    "        mse = mean_squared_error(Ypred,test_Y)\n",
    "        mae = mean_absolute_error(Ypred,test_Y)\n",
    "        r_score = r2_score(Ypred,test_Y)\n",
    "        accuracy = r_score*100\n",
    "        print(\"Accuracy by r2 score is = {}\".format(accuracy))\n",
    "#         print(\"mae: {}, mse: {}, r2 score: {}\".format(mae,mse,r_score))\n",
    "        \n",
    "        # plotting\n",
    "        self.plotter(train_data,train_Y,reg,'train data vs predicted')\n",
    "        self.plotter(test_data,test_Y,reg,'test data vs predicted')\n",
    "    \n",
    "    def learning_curve(self,algo,features,output,train_sizes,cv_val):\n",
    "        train_sizes, train_scores,validation_scores = learning_curve(\n",
    "            estimator=algo,\n",
    "            X=features,\n",
    "            y=output,\n",
    "            train_sizes=train_sizes,\n",
    "            cv=cv_val,\n",
    "            scoring = 'neg_mean_squared_error'\n",
    "        )\n",
    "        print('Train scores: \\n{}\\n Validation scores: \\n{}\\n'.format(train_scores,validation_scores))\n",
    "        train_mean= -np.mean(train_scores,axis=1)\n",
    "        valid_mean= np.mean(validation_scores,axis=1)\n",
    "#         print(train_mean,valid_mean)\n",
    "        plt.plot(train_sizes,train_mean,label='training error curve',color='g')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.plot(train_sizes,valid_mean,label='validation error curve',color='r')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def cross_validation(dataframe):\n",
    "        from sklearn.cross_validation import cross_validation\n",
    "        \n",
    "        \n",
    "    def validation_Curve(self,algo,features,output,cv_val):\n",
    "        param_range = np.logspace(-6,-1,cv_val)\n",
    "        \n",
    "        train_scores, test_scores = validation_curve(\n",
    "        algo, param_name=\"max_depth\", X=features,y=output\n",
    "        ,param_range=param_range, cv=10, scoring=\"r2\"\n",
    "        )\n",
    "        train_mean=np.mean(train_scores,axis=1)\n",
    "        test_mean= np.mean(test_scores,axis=1)\n",
    "        train_std =np.std(train_scores,axis=1)\n",
    "        test_std =np.std(test_scores,axis=1)\n",
    "        plt.ylim(0.0,0.2)\n",
    "\n",
    "#         viz= validation_curve(\n",
    "#         algo, param_name=\"max_depth\", X=features,y=output\n",
    "#         ,param_range=param_range, cv=10, scoring=\"r2\"\n",
    "#         )\n",
    "        \n",
    "        plt.title('validation curve for random forest')\n",
    "        plt.semilogx(param_range, train_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=2)\n",
    "        plt.fill_between(param_range, train_mean - train_std,\n",
    "                 train_mean + train_std, alpha=0.1,\n",
    "                 color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(param_range, train_mean, label=\"Validatgion score\",\n",
    "             color=\"g\", lw=2)\n",
    "        plt.fill_between(param_range, test_mean - train_std,\n",
    "                 train_mean + train_std, alpha=0.1,\n",
    "                 color='g', lw=2)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def main(self,dataframe):\n",
    "        try:\n",
    "            train_sizes = [1,50,100,200,500,2000,5000,7000,9000,12000,13000]\n",
    "            self.Random_Forest_Regression_demo(dataframe)\n",
    "            self.learning_curve(RandomForestRegressor(),dataframe.drop('y',axis=1),dataframe['y'],train_sizes,5)\n",
    "            \n",
    "            self.validation_Curve(DecisionTreeRegressor(),dataframe.drop('y',axis=1),dataframe['y'],5)\n",
    "        except Exception as e:\n",
    "            print(\"Process stopped because \",e)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     obj = Random_Forest_Regression()\n",
    "#     obj.main(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Random_Forest_Regression()\n",
    "train_sizes = [1,50,100,200,500,2000,5000,7000,9000,12000,13000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = dataframe['weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.learning_curve(RandomForestRegressor(),dataframe.drop('y',axis=1),dataframe['y'],train_sizes,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we see the curve is converging it shows we have high bais and low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.validation_Curve(RandomForestRegressor(),dataframe.drop('y',axis=1),dataframe['y'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "\n",
    "#loading the dataset\n",
    "# dataset = pd.read_csv('dataset-4.csv')\n",
    "#X = dataset.iloc[:,0:6].values\n",
    "\n",
    "X = dataframe.drop('y',axis=1).values\n",
    "y = dataframe['y'].values\n",
    "\n",
    "#train/test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#fitting the classifier to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Then we create the CAP Curve with the following code :\n",
    "\n",
    "# The ‘capcurve’ function that builds and shows the CAP curve is defined as follows :\n",
    "\n",
    "from scipy import integrate\n",
    "def capcurve(y_values, y_preds_proba):\n",
    "    num_pos_obs = np.sum(y_values)\n",
    "    num_count = y_values.shape[0]\n",
    "    rate_pos_obs = np.divide(float(num_pos_obs) , float(num_count))\n",
    "    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n",
    "    xx = np.divide(np.arange(num_count), float(num_count - 1))\n",
    "\n",
    "    y_cap = np.c_[y_values,y_preds_proba]\n",
    "    y_cap_df_s = pd.DataFrame(data=y_cap)\n",
    "    y_cap_df_s = y_cap_df_s.sort_values([1],ascending=False).reset_index('index', drop=True)\n",
    "\n",
    "    print(y_cap_df_s.head(20))\n",
    "\n",
    "    yy = np.cumsum(np.divide(y_cap_df_s[0]),float(num_pos_obs))\n",
    "    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n",
    "\n",
    "    percent = 0.5\n",
    "    row_index = np.trunc(np.multiply(num_count, percent))\n",
    "\n",
    "    val_y1 = yy[row_index]\n",
    "    val_y2 = yy[row_index+1]\n",
    "    if val_y1 == val_y2:\n",
    "        val = val_y1*1.0\n",
    "    else:\n",
    "        val_x1 = xx[row_index]\n",
    "        val_x2 = xx[row_index+1]\n",
    "    val = np.add(val_y1, np.divide(np.subtract(val_x2 , percent),np.subtract(val_x2, val_x1))*np.subtract(val_y2, val_y1))\n",
    "    sigma_ideal = 1 * np.divide(xx[num_pos_obs - 1 ] ,2) + np.subtract(xx[num_count - 1], xx[num_pos_obs]) * 1\n",
    "    sigma_model = integrate.simps(yy,xx)\n",
    "    sigma_random = integrate.simps(xx,xx)\n",
    "\n",
    "    ar_value = (sigma_model - sigma_random) / (sigma_ideal - sigma_random)\n",
    "    #ar_label = 'ar value = %s' % ar_value\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "    ax.plot(ideal['x'],ideal['y'], color='grey', label='Perfect Model')\n",
    "    ax.plot(xx,yy, color='red', label='User Model')\n",
    "    #ax.scatter(xx,yy, color='red')\n",
    "    ax.plot(xx,xx, color='blue', label='Random Model')\n",
    "    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=1)\n",
    "    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=1, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n",
    "\n",
    "    plt.xlim(0, 1.02)\n",
    "    plt.ylim(0, 1.25)\n",
    "    plt.title(\"CAP Curve - a_r value =\"+str(ar_value))\n",
    "    plt.xlabel('% of the data')\n",
    "    plt.ylabel('% of positive obs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "y_pred = regressor.predict(X=X_test)\n",
    "capcurve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
