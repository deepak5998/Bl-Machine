{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction:\n",
    "# creates the new features <= the number of features originally from the independent variables which gives most variance of the dataset without the dependent variables.\n",
    "# As it does not considers the dependent variable it can be used for unspervised learning. WE can get 2 or 3 variables only so we can even visualise easily in 2 or 3 features easily.\n",
    "# These indepnedent variables with highest variance so we can use them and also we cna use for visualization. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pickle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/Wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isna().sum()\n",
    "# shows no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.boxplot(figsize=(10,10),rot=45)\n",
    "# shows some anamoly in magnesium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe,test = train_test_split(dataframe,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataframe.drop(['Customer_Segment'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = dataframe['Customer_Segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_cross_val,Y_train,Y_cross_val = train_test_split(X_train,Y_train,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_cross_val = ss.transform(X_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA: Extracts new n <= number of features in original, based on the classes of dependent variable. Hence it is a supervised dimentionality reduction model.\n",
    "# n_component number of the components we want to extract from our dataset.\n",
    "lda = LDA(n_components=2) # 2 new extracted features\n",
    "\n",
    "X_train = lda.fit_transform(X_train,Y_train)\n",
    "X_cross_val = lda.transform(X_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_cross_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy by accuracy: {}\".format(accuracy_score(Y_cross_val,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plotting:\n",
    "    def plotter(self,X_train,Y_train,classifier,title):\n",
    "        X1_grid, X2_grid = np.meshgrid(np.arange(start=X_train[:,0].min()-1,stop=X_train[:,0].max()+1,step=0.01),\n",
    "                                       np.arange(start=X_train[:,1].min()-1,stop=X_train[:,1].max()+1,step=0.01))\n",
    "\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.contourf(X1_grid,X2_grid,classifier.predict(np.array([X1_grid.ravel(),X2_grid.ravel()]).T).reshape(X1_grid.shape)\n",
    "                     ,alpha=0.75, cmap = ListedColormap(('#ff2a16','#35ff16','gold')))\n",
    "        plt.title(title)\n",
    "        plt.xlim(X1_grid.min(),X1_grid.max())\n",
    "        plt.ylim(X2_grid.min(),X2_grid.max())\n",
    "        for i,j in enumerate(np.unique(Y_train)):\n",
    "            plt.scatter(X_train[Y_train==j,0],X_train[Y_train==j,1],\n",
    "                        c = ListedColormap(('red','green','yellow'))(i),label=j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotting()\n",
    "plot.plotter(X_train,Y_train,classifier,\"training separation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotting()\n",
    "plot.plotter(X_cross_val,Y_cross_val,classifier,\"Cross_validator separation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LDA/pickle/model.pkl','wb') as f:\n",
    "    pickle.dump(ss,f)\n",
    "    pickle.dump(lda,f)\n",
    "    pickle.dump(classifier,f)\n",
    "    pickle.dump(plot ,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
